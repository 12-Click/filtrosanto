<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Lens with TensorFlow.js</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: black;
        }

        #camera-container {
            position: relative;
        }

        #video {
            width: 100%;
            height: auto;
            transform: scaleX(-1); /* Mirror the video */
        }

        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        #halo {
            position: absolute;
            width: 50%;
            top: 20%;
            transform: translateX(-50%);
        }

        #text {
            position: absolute;
            bottom: 20%;
            transform: translateX(-50%);
        }
    </style>
</head>
<body>
    <div id="camera-container">
        <video id="video" autoplay playsinline></video>
        <div id="overlay">
            <img id="halo" src="images/halo.gif" alt="Halo" />
            <img id="text" src="images/text.gif" alt="Text" />
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <script>
        const video = document.getElementById('video');
        const halo = document.getElementById('halo');
        const text = document.getElementById('text');

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true
            });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function detectFace() {
            const model = await faceLandmarksDetection.load(
                faceLandmarksDetection.SupportedPackages.mediapipeFacemesh
            );
            const detect = async () => {
                const predictions = await model.estimateFaces({ input: video });
                if (predictions.length > 0) {
                    const { boundingBox } = predictions[0];
                    halo.style.left = `${boundingBox.topLeft[0] + boundingBox.bottomRight[0] / 2}px`;
                    halo.style.top = `${boundingBox.topLeft[1]}px`;
                    text.style.left = `${boundingBox.topLeft[0] + boundingBox.bottomRight[0] / 2}px`;
                    text.style.top = `${boundingBox.bottomRight[1]}px`;
                }
                requestAnimationFrame(detect);
            };
            detect();
        }

        async function main() {
            await setupCamera();
            video.play();
            detectFace();
        }

        main();
    </script>
</body>
</html>