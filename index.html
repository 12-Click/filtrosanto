<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Face Lens</title>
  <style>
    /* Fullscreen setup and styling */
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
      background-color: #000;
    }
    #video {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      z-index: 1;
    }
    #halo, #text {
      position: absolute;
      z-index: 2;
      display: none; /* Initially hidden */
    }
    #halo {
      width: 150px;
    }
    #text {
      width: 200px;
    }
  </style>
</head>
<body>

<!-- Video feed from camera -->
<video id="video" autoplay muted playsinline></video>

<!-- GIF elements -->
<img id="halo" src="images/halo.gif" alt="Halo GIF">
<img id="text" src="images/text.gif" alt="Text GIF">

<!-- JavaScript for face tracking -->
<script src="https://cdn.jsdelivr.net/npm/clmtrackr@1.1.2/build/clmtrackr.min.js"></script>
<script>
  const video = document.getElementById('video');
  const halo = document.getElementById('halo');
  const text = document.getElementById('text');
  let tracker;

  // Set up the video stream from the user's camera
  async function startVideo() {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
    } catch (error) {
      console.error("Camera not accessible:", error);
    }
  }

  // Initialize clmtrackr and start tracking
  function startTracking() {
    tracker = new clm.tracker();
    tracker.init();
    tracker.start(video);

    // Continuously update GIF positions
    requestAnimationFrame(updatePositions);
  }

  // Update positions based on tracking points
  function updatePositions() {
    const positions = tracker.getCurrentPosition();

    if (positions) {
      // Show the GIFs if face is detected
      halo.style.display = "block";
      text.style.display = "block";

      // Position halo slightly above the head (forehead point, index 33)
      const foreheadX = positions[33][0];
      const foreheadY = positions[33][1];
      halo.style.left = `${foreheadX - halo.width / 2}px`;
      halo.style.top = `${foreheadY - halo.height - 20}px`;

      // Position text under the chin (chin point, index 7)
      const chinX = positions[7][0];
      const chinY = positions[7][1];
      text.style.left = `${chinX - text.width / 2}px`;
      text.style.top = `${chinY + 10}px`;
    } else {
      // Hide the GIFs if no face is detected
      halo.style.display = "none";
      text.style.display = "none";
    }

    requestAnimationFrame(updatePositions);
  }

  // Start video and tracking when the page loads
  window.onload = async () => {
    await startVideo();
    startTracking();
  };
</script>
</body>
</html>