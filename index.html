<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>San Francisco Javier</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            height: 100vh;
            background: url('https://your-image-url.com/background.jpg') no-repeat center center fixed; /* Background image */
            background-size: cover;
        }

        video {
            position: absolute; /* Set video to absolute position */
            top: 0;
            left: 0;
            width: 100vw; /* Make the video take full width */
            height: 100vh; /* Make the video take full height */
            object-fit: cover; /* Cover the entire area */
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1; /* Ensure canvas is on top of video */
            width: 100vw; /* Full width */
            height: 100vh; /* Full height */
        }

        .icon {
            position: absolute;
            top: 20px; /* Distance from the top */
            right: 20px; /* Distance from the right */
            width: 50px; /* Adjust icon size */
            cursor: pointer;
            z-index: 2; /* Ensure icon is above the canvas */
        }

        img {
            display: none; /* Initially hide the captured photo */
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://unpkg.com/@tensorflow/tfjs"></script>
    <script src="https://unpkg.com/@tensorflow-models/face-landmarks-detection"></script>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
    <img id="cameraIcon" class="icon" src="images/angel.png" alt="Capture" /> <!-- Replace with your camera icon URL -->
    <img id="capturedPhoto" alt="Captured Photo" style="display:none;"/> <!-- Hidden image for captured photo -->
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const capturedPhoto = document.getElementById('capturedPhoto');

        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } }); // Use front camera
                video.srcObject = stream;

                return new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play(); // Play the video after metadata is loaded
                        resolve(video);
                    };
                });
            } catch (error) {
                console.error("Error accessing the camera: ", error);
                alert("Could not access the camera. Please check your permissions.");
            }
        }

        async function loadFaceLandmarksModel() {
            const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
            return await faceLandmarksDetection.load(model);
        }

        async function main() {
            await setupCamera();
            const model = await loadFaceLandmarksModel();
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const detectFace = async () => {
                ctx.clearRect(0, 0, canvas.width, canvas.height); // Clear previous drawings
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height); // Draw video frame

                const predictions = await model.estimateFaces({ input: video });

                console.log("Predictions:", predictions); // Log predictions for debugging

                if (predictions.length > 0) {
                    predictions.forEach((prediction) => {
                        const keypoints = prediction.scaledMesh;

                        console.log("Detected keypoints:", keypoints); // Log keypoints for debugging

                        const x = keypoints[30][0]; // Nose tip
                        const y = keypoints[30][1] - 100; // Position above the head for the halo

                        // Draw a red square where the face is detected
                        ctx.fillStyle = 'red'; 
                        ctx.fillRect(x - 10, y - 10, 20, 20); // Draw a red square
                    });
                }

                requestAnimationFrame(detectFace);
            };

            detectFace();

            // Capture photo functionality
            document.getElementById('cameraIcon').addEventListener('click', () => {
                // Draw video frame to canvas
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height); 
                const photo = canvas.toDataURL('image/png'); // Capture the canvas as a PNG
                capturedPhoto.src = photo; // Set the src of the img element to the captured photo
                capturedPhoto.style.display = 'block'; // Show the captured photo
                console.log(photo); // Log the captured photo data URL to the console
            });
        }

        main();
    </script>
</body>
</html>